{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"L4","authorship_tag":"ABX9TyOsch7m8qPT7C/R8uXFoNhH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# To load fine-tuned model and generate test sentences"],"metadata":{"id":"iFKl3rlloL64"}},{"cell_type":"code","source":["# load dataset\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cw_nakv4oU-e","executionInfo":{"status":"ok","timestamp":1746090851085,"user_tz":-120,"elapsed":69617,"user":{"displayName":"cmp","userId":"07760488268921953080"}},"outputId":"f9d47367-f63b-4ef9-e15e-706884fa556f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import time\n","import gc\n","import pandas as pd\n","from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline as hf_pipeline\n","import torch\n","\n","# Settings\n","model_id = \"charlotte657/lora-sealion-finetuned-1\"\n","csv_path = \"/content/drive/MyDrive/test-set/test-tweets-english.csv\"\n","output_csv_path = \"/content/drive/MyDrive/results/2022-tweets-ft/taglish-5-outputs.csv\" # ‚Üê change as needed\n","batch_size = 4  # Adjust based on your GPU memory\n","\n","# Load the test sentences\n","df = pd.read_csv(csv_path)\n","df.rename(columns={df.columns[0]: \"english_tweet\"}, inplace=True)\n","test_sentences = df[\"english_tweet\"].tolist()"],"metadata":{"id":"_UcF_rqFoLkO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load model and tokenizer\n","model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16, device_map=\"auto\")\n","tokenizer = AutoTokenizer.from_pretrained(model_id)\n","\n","# Create generation pipeline\n","text_generator = hf_pipeline(\n","    \"text-generation\",\n","    model=model,\n","    tokenizer=tokenizer,\n","    torch_dtype=torch.bfloat16,\n","    device_map=\"auto\",\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"id":"1fzFhPzF7IZo","executionInfo":{"status":"error","timestamp":1746791385030,"user_tz":-120,"elapsed":76,"user":{"displayName":"cmp","userId":"07760488268921953080"}},"outputId":"f5ba8cd1-c9be-4bc7-df27-23a6370607e1"},"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'AutoModelForCausalLM' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-ff8f45f4828a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load model and tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbfloat16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Create generation pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'AutoModelForCausalLM' is not defined"]}]},{"cell_type":"code","source":["# GENERATE CODE SWITCHED TRANSLATIONS\n","\n","def generate_code_switched_text(text, prompt_type=\"english\"):\n","    # Modify prompts here\n","    if prompt_type == \"english\":\n","        prompt = f\"You are a machine translation system that translates sentences in the Tweet domain. Please translate this Tweet from English to bilingual code-switching of Tagalog and English. Do not output any additional text other than the translation.\\n\\n{text}\\n\\nTranslation:\"\n","    elif prompt_type == \"taglish\":\n","        prompt = f\"Isa kang machine translation system na nagta-translate ng mga sentences sa Tweet domain. Paki translate itong Tweet from English to bilingual code-switching ng Tagalog at English. Huwag kang mag-output ng kahit anong additional text maliban sa translation.\\n\\n{text}\\n\\nTranslation:\"\n","    elif prompt_type == \"english-fewshot\":\n","        prompt = f\"\"\"You are a machine translation system that translates sentences in the Tweet domain. Below are examples:\n","Example 1:\n","English: It seems scary to try the chicken sandwich from Jollibee hmm i saw a lot of raw parts\n","Taglish: parang ang skeri tuloy tikman nung chicken sandwich sa jollibee hmmm dame ko nakikitang hilaw\n","\n","Example 2:\n","English: You're really brutal with your suggestions\n","Taglish: Bangis mo talaga sa mga suggestions mo\n","\n","Example 3:\n","English: There's always that child that has the same attitude of a dad, one that is really mischievous. Huhuhu Yuri ily\n","Taglish: there's always that child talaga na sobrang kaugali ng tatay na sobrang ma loko huhuhu yuri ily po\n","\n","Example 4:\n","English: Foreshadowing to the author.. I feel nervous until the end, because there's a limit...can't it just be forever? ‚Äî Let's do forever next time\n","Taglish: Foreshadowing to author..kinakabahan ako sa hanggang dulo, kasi may hangganan eh...di ba pwedeng palagi na lang? ‚Äî Sige gawin nating palagi next time\n","\n","Example 5:\n","English: Ate Ella, i can follow right? I believe this is me because my birthday is soon ü§©\n","Taglish: pde naman humabol ate ella di ba? i believe ako na to dahil malapit na ang bday ko ü§©\n","\n","Example 6:\n","English: If all of this has to do with boundaries, that BB addressed the other day, then it is management's fault. Why wasn't it addressed directly to TJ? It should have been for him anyway.\n","Taglish: Kung may kinalaman ang lahat ng ito sa 'boundaries' na niaddress ni BB noong isang araw, then kasalanan to ng management, bakit hindi na lang kasi direktang inaddress kay TJ total para sa kanya naman talaga dapat yun.\n","\n","Example 7:\n","English: I don't care, whatever. You changed anyway right?\n","Taglish: idc, bahala ka. U changed naman na di ba?\n","\n","Example 8:\n","English: hahahaha, fuck. Sometimes I'm really too lazy to reply. If I'm in the mood, that's the only time I'll reply. Hahaha but anyway, thank you! I appreciate your kind words for me! Love lots!!\n","Taglish: hahahaha, taena minsan tamad talaga ako mag reply pag asa mood ako tsaka lang ako mag rereply hahaha but anw, thank you! i appreciate your kind words for me! love lots !!\n","\n","Example 9:\n","English: I want to finish it but fuck\n","Taglish: i wanna finish it pero tanhina talaga\n","\n","Example 10:\n","English: I am actually angry. They used 875 again for views\n","Taglish: Galit ako actually. Ginamit na naman nila 875 para sa views\n","\n","Please translate this Tweet from English to bilingual code-switching of Tagalog and English. Do not output any additional text other than the translation.\n","English: {text}\n","Taglish:\n","\"\"\"\n","    elif prompt_type == \"taglish-fewshot\":\n","        prompt = f\"\"\"Isa kang machine translation system na nagta-translate ng mga sentences sa Tweet domain. Below ang ilang halimbawa:\n","Halimbawa 1:\n","English: It seems scary to try the chicken sandwich from Jollibee hmm i saw a lot of raw parts\n","Taglish: parang ang skeri tuloy tikman nung chicken sandwich sa jollibee hmmm dame ko nakikitang hilaw\n","\n","Halimbawa 2:\n","English: You're really brutal with your suggestions\n","Taglish: Bangis mo talaga sa mga suggestions mo\n","\n","Halimbawa 3:\n","English: There's always that child that has the same attitude of a dad, one that is really mischievous. Huhuhu Yuri ily\n","Taglish: there's always that child talaga na sobrang kaugali ng tatay na sobrang ma loko huhuhu yuri ily po\n","\n","Halimbawa 4:\n","English: Foreshadowing to the author.. I feel nervous until the end, because there's a limit...can't it just be forever? ‚Äî Let's do forever next time\n","Taglish: Foreshadowing to author..kinakabahan ako sa hanggang dulo, kasi may hangganan eh...di ba pwedeng palagi na lang? ‚Äî Sige gawin nating palagi next time\n","\n","Halimbawa 5:\n","English: Ate Ella, i can follow right? I believe this is me because my birthday is soon ü§©\n","Taglish: pde naman humabol ate ella di ba? i believe ako na to dahil malapit na ang bday ko ü§©\n","\n","Halimbawa 6:\n","English: If all of this has to do with boundaries, that BB addressed the other day, then it is management's fault. Why wasn't it addressed directly to TJ? It should have been for him anyway.\n","Taglish: Kung may kinalaman ang lahat ng ito sa 'boundaries' na niaddress ni BB noong isang araw, then kasalanan to ng management, bakit hindi na lang kasi direktang inaddress kay TJ total para sa kanya naman talaga dapat yun.\n","\n","Halimbawa 7:\n","English: I don't care, whatever. You changed anyway right?\n","Taglish: idc, bahala ka. U changed naman na di ba?\n","\n","Halimbawa 8:\n","English: hahahaha, fuck. Sometimes I'm really too lazy to reply. If I'm in the mood, that's the only time I'll reply. Hahaha but anyway, thank you! I appreciate your kind words for me! Love lots!!\n","Taglish: hahahaha, taena minsan tamad talaga ako mag reply pag asa mood ako tsaka lang ako mag rereply hahaha but anw, thank you! i appreciate your kind words for me! love lots !!\n","\n","Halimbawa 9:\n","English: I want to finish it but fuck\n","Taglish: i wanna finish it pero tanhina talaga\n","\n","Halimbawa 10:\n","English: I am actually angry. They used 875 again for views\n","Taglish: Galit ako actually. Ginamit na naman nila 875 para sa views\n","\n","Paki translate itong Tweet from English to bilingual code-switching ng Tagalog at English. Huwag kang mag-output ng kahit anong additional text maliban sa translation.\n","English: {text}\n","Taglish:\n","\"\"\"\n","    elif prompt_type == \"english-fewshot-5\":\n","        prompt = f\"\"\"You are a machine translation system that translates sentences in the Tweet domain. Below are examples:\n","Example 1:\n","English: You're really brutal with your suggestions\n","Taglish: Bangis mo talaga sa mga suggestions mo\n","\n","Example 2:\n","English: There's always that child that has the same attitude of a dad, one that is really mischievous. Huhuhu Yuri ily\n","Taglish: there's always that child talaga na sobrang kaugali ng tatay na sobrang ma loko huhuhu yuri ily po\n","\n","Example 3:\n","English: Foreshadowing to the author.. I feel nervous until the end, because there's a limit...can't it just be forever? ‚Äî Let's do forever next time\n","Taglish: Foreshadowing to author..kinakabahan ako sa hanggang dulo, kasi may hangganan eh...di ba pwedeng palagi na lang? ‚Äî Sige gawin nating palagi next time\n","\n","Example 4:\n","English: I don't care, whatever. You changed anyway right?\n","Taglish: idc, bahala ka. U changed naman na di ba?\n","\n","Example 5:\n","English: hahahaha, fuck. Sometimes I'm really too lazy to reply. If I'm in the mood, that's the only time I'll reply. Hahaha but anyway, thank you! I appreciate your kind words for me! Love lots!!\n","Taglish: hahahaha, taena minsan tamad talaga ako mag reply pag asa mood ako tsaka lang ako mag rereply hahaha but anw, thank you! i appreciate your kind words for me! love lots !!\n","\n","Please translate this Tweet from English to bilingual code-switching of Tagalog and English. Do not output any additional text other than the translation.\n","English: {text}\n","Taglish:\n","\"\"\"\n","    elif prompt_type == \"taglish-fewshot-5\":\n","        prompt = f\"\"\"Isa kang machine translation system na nagta-translate ng mga sentences sa Tweet domain. Below ang ilang halimbawa:\n","Halimbawa 1:\n","English: You're really brutal with your suggestions\n","Taglish: Bangis mo talaga sa mga suggestions mo\n","\n","Halimbawa 2:\n","English: There's always that child that has the same attitude of a dad, one that is really mischievous. Huhuhu Yuri ily\n","Taglish: there's always that child talaga na sobrang kaugali ng tatay na sobrang ma loko huhuhu yuri ily po\n","\n","Halimbawa 3:\n","English: Foreshadowing to the author.. I feel nervous until the end, because there's a limit...can't it just be forever? ‚Äî Let's do forever next time\n","Taglish: Foreshadowing to author..kinakabahan ako sa hanggang dulo, kasi may hangganan eh...di ba pwedeng palagi na lang? ‚Äî Sige gawin nating palagi next time\n","\n","Halimbawa 4:\n","English: I don't care, whatever. You changed anyway right?\n","Taglish: idc, bahala ka. U changed naman na di ba?\n","\n","Halimbawa 5:\n","English: hahahaha, fuck. Sometimes I'm really too lazy to reply. If I'm in the mood, that's the only time I'll reply. Hahaha but anyway, thank you! I appreciate your kind words for me! Love lots!!\n","Taglish: hahahaha, taena minsan tamad talaga ako mag reply pag asa mood ako tsaka lang ako mag rereply hahaha but anw, thank you! i appreciate your kind words for me! love lots !!\n","\n","Paki translate itong Tweet from English to bilingual code-switching ng Tagalog at English. Huwag kang mag-output ng kahit anong additional text maliban sa translation.\n","English: {text}\n","Taglish:\n","\"\"\"\n","    else:\n","        print(\"Warning: Unknown prompt_type. Falling back to 'english'.\")\n","        prompt = f\"You are a machine translation system that translates sentences in the Tweet domain. Please translate this Tweet from English to bilingual code-switching of Tagalog and English. Do not output any additional text other than the translation.\\n\\n{text}\\n\\nTranslation:\"\n","\n","    messages = [{\"role\": \"user\", \"content\": prompt}]\n","    output = text_generator(prompt, max_new_tokens=100) # look at max_new_tokens if it crashes. Could modify temp and do_sample here but im not.\n","    return output[0][\"generated_text\"]\n"],"metadata":{"id":"iCWQGKYKziq6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load test sentences\n","df = pd.read_csv(csv_path)\n","df.rename(columns={df.columns[0]: \"english_tweet\"}, inplace=True)\n","\n","# Batch processing and saving\n","results = []\n","\n","prompt_type=\"taglish-fewshot-5\" # ‚Üê change as needed\n","\n","for i, row in df.iterrows():\n","    eng_text = row[\"english_tweet\"]\n","    translated_text = generate_code_switched_text(eng_text, prompt_type=prompt_type)\n","    results.append((eng_text, translated_text))\n","\n","    if (i + 1) % batch_size == 0:\n","        temp_df = pd.DataFrame(results, columns=[\"english_text\", \"code_switched_text\"])\n","        temp_df.to_csv(output_csv_path, mode=\"a\", header=not bool(i), index=False)\n","        results = []\n","        print(f\"Saved progress at {i+1} sentences.\")\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    time.sleep(0.5)\n","\n","# Final save\n","final_df = pd.DataFrame(results, columns=[\"english_text\", \"code_switched_text\"])\n","final_df.to_csv(output_csv_path, mode=\"a\", header=False, index=False)\n","\n","print(f\"‚úÖ Finished processing! Saved results to {output_csv_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P7ob0QNewq-y","executionInfo":{"status":"ok","timestamp":1746091866519,"user_tz":-120,"elapsed":405212,"user":{"displayName":"cmp","userId":"07760488268921953080"}},"outputId":"882741c3-3cb5-449e-a33f-25f35d5c444a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved progress at 4 sentences.\n","Saved progress at 8 sentences.\n","Saved progress at 12 sentences.\n","Saved progress at 16 sentences.\n","Saved progress at 20 sentences.\n","Saved progress at 24 sentences.\n","Saved progress at 28 sentences.\n","Saved progress at 32 sentences.\n","Saved progress at 36 sentences.\n","Saved progress at 40 sentences.\n","Saved progress at 44 sentences.\n","Saved progress at 48 sentences.\n","Saved progress at 52 sentences.\n","Saved progress at 56 sentences.\n","Saved progress at 60 sentences.\n","Saved progress at 64 sentences.\n","Saved progress at 68 sentences.\n","Saved progress at 72 sentences.\n","Saved progress at 76 sentences.\n","Saved progress at 80 sentences.\n","Saved progress at 84 sentences.\n","Saved progress at 88 sentences.\n","Saved progress at 92 sentences.\n","Saved progress at 96 sentences.\n","Saved progress at 100 sentences.\n","‚úÖ Finished processing! Saved results to /content/drive/MyDrive/results/2022-tweets-ft/taglish-5-outputs.csv\n"]}]}]}